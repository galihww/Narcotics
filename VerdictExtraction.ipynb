{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load keywords from a file\n",
    "def load_keywords_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        keywords = json.load(file)\n",
    "    return keywords\n",
    "\n",
    "# Extract \"No Putusan\"\n",
    "def extract_no_putusan(content):\n",
    "    pattern = r\"(Nomor\\s*[:\\-]?\\s*\\d+/[A-Za-z.]+/\\d+/[A-Za-z\\s\\-]{1,7})\"\n",
    "    match = re.search(pattern, content)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Extract \"Lembaga Peradilan\"\n",
    "def extract_lembaga_peradilan(content):\n",
    "    pattern = r\"(Pengadilan\\s*(Negeri|Agama|Tinggi)(\\s*di)?\\s*\\w+)(?!\\w)\"\n",
    "    match = re.search(pattern, content)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Extract data from content using keywords\n",
    "def extract_data_from_content(content, keywords):\n",
    "    extracted_texts = []\n",
    "    extracted_ranges = []\n",
    "\n",
    "    for keyword in keywords:\n",
    "        pattern = re.escape(keyword)\n",
    "        match = re.search(pattern, content, re.IGNORECASE)\n",
    "\n",
    "        if match:\n",
    "            start_index = match.start()\n",
    "            end_index = content.find('\\n\\n', start_index)\n",
    "            end_index = end_index if end_index != -1 else len(content)\n",
    "\n",
    "            overlaps = any(start <= start_index <= end or start <= end_index <= end for start, end in extracted_ranges)\n",
    "            if overlaps:\n",
    "                continue\n",
    "\n",
    "            extracted_paragraph = content[start_index:end_index].strip()\n",
    "\n",
    "            while extracted_paragraph.count('.') < 5:\n",
    "                additional_end_index = content.find('\\n\\n', end_index + 2)\n",
    "                additional_end_index = additional_end_index if additional_end_index != -1 else len(content)\n",
    "                extracted_paragraph += content[end_index:additional_end_index].strip()\n",
    "                end_index = additional_end_index\n",
    "\n",
    "            extracted_texts.append(extracted_paragraph)\n",
    "            extracted_ranges.append((start_index, end_index))\n",
    "\n",
    "    consolidated_text = \"\\n\\n\".join(extracted_texts)\n",
    "    return consolidated_text if consolidated_text else None\n",
    "\n",
    "# Extract paragraph related to 'wanprestasi'\n",
    "def extract_wanprestasi_paragraph(content):\n",
    "    pattern = r\"(Tergugat\\stelah\\smelakukan(?:perbuatan\\s)?wanprestasi.*?)(?:\\n\\n|\\Z)\"\n",
    "    match = re.search(pattern, content)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Extract data from a file\n",
    "def extract_data_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    extracted_data = {category: None for category in KEYWORDS.keys()}\n",
    "\n",
    "    extracted_data[\"No Putusan\"] = extract_no_putusan(content)\n",
    "    extracted_data[\"Lembaga Peradilan\"] = extract_lembaga_peradilan(content)\n",
    "    extracted_data[\"Perihal Gugatan\"] = extract_wanprestasi_paragraph(content)\n",
    "    extracted_data[\"Identitas Para Pihak\"] = extract_data_from_content(content, KEYWORDS[\"Identitas Para Pihak\"])\n",
    "\n",
    "    for category, keywords in KEYWORDS.items():\n",
    "        if category not in [\"No Putusan\", \"Lembaga Peradilan\", \"Perihal Gugatan\", \"Identitas Para Pihak\"]:\n",
    "            extracted_data[category] = extract_data_from_content(content, keywords)\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "# Clean illegal characters for Excel\n",
    "def clean_illegal_characters(data):\n",
    "    cleaned_data = {k: re.sub(r'[\\x00-\\x1F\\x7F]', ' ', v) if v else v for k, v in data.items()}\n",
    "    return cleaned_data\n",
    "\n",
    "# Save data to an Excel file\n",
    "def save_to_excel(data, output_file):\n",
    "    cleaned_data = {filename: clean_illegal_characters(file_data) for filename, file_data in data.items()}\n",
    "    df = pd.DataFrame(cleaned_data).transpose()\n",
    "    df = df.fillna(\"False\")\n",
    "    df.to_excel(output_file, index_label=\"File Name\")\n",
    "\n",
    "# Read files from a folder and extract data to Excel\n",
    "def read_folder_and_extract_data(folder_path, output_file_path):\n",
    "    all_extracted_data = {}\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            all_extracted_data[file_name] = extract_data_from_file(file_path)\n",
    "\n",
    "    save_to_excel(all_extracted_data, output_file_path)\n",
    "\n",
    "# Executing the extraction process\n",
    "KEYWORDS = load_keywords_from_file('keywords.txt')\n",
    "source_folder = 'putusan/'\n",
    "destination_file = 'Data.xlsx'\n",
    "read_folder_and_extract_data(source_folder, destination_file)"
   ],
   "id": "863e28d2147048d4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
